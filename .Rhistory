sd_function_arguments_fixed = list(),
sd_function_arguments_random = list())
# Assign the control parameters! (Hier wäre vielleicht eine control function
# cool, die alles was nicht übergeben wird auffüllt!)
list2env(control_mean_sd, envir = environment())
# Remove a possible intercept column from X and Z (in all cases -->
# die fügen wir immer von Hand dazu!)
if (length(unique(X[, 1])) == 1)  X <- X[, -1, drop = FALSE]
if (length(unique(Z[, 1])) == 1)  Z <- Z[, -1, drop = FALSE]
# Welche Spalte von X korrespondiert zu welcher Spalte in Z? Sollen wir einfach
# vorschreiben dass die richtig sortiert sind?
# For now mal schon!
Z_matching <- as.logical(apply(Z, 2, function(z) sum(apply(X, 2, function(x) all(z == x)))))
X_matching <- as.logical(apply(X, 2, function(z) sum(apply(Z, 2, function(x) all(z == x)))))
if (intercepts$fixed & intercepts$random) X_matching <- c(TRUE, X_matching)
intercepts = list(random = TRUE, fixed = TRUE)
if (intercepts$fixed & intercepts$random) X_matching <- c(TRUE, X_matching)
# Set the model dimensions
n <- nrow(X)
p <- ncol(X) + intercepts$fixed
k <- ncol(Z) + intercepts$random
# Fit the first regression
m <- ranklm(X = X, y = y, intercept = intercepts$fixed, weighted = weighted,
leverage_columns = leverage_columns,
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_fixed)
leverage_columns = 1:ncol(X)
weighted=TRUE
# Fit the first regression
m <- ranklm(X = X, y = y, intercept = intercepts$fixed, weighted = weighted,
leverage_columns = leverage_columns,
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_fixed)
# Coefficients and predicted values
beta_hat <- m$coef
y_hat <- { if (intercepts$fixed) { cbind(1, X) } else { X } } %*% beta_hat
weights <- m$weights
weights
# Calculate the residuals
marg_residuals <- y - y_hat
# Predict the random effects
groupwise_models <- lapply(1:n.groups, function(i) {
x = group_limits[i, ]
ranklm(y = marg_residuals[x[1]:x[2]],
X = Z[x[1]:x[2], , drop = FALSE],
intercept = intercepts$random,
weighted = weight_re, weights = groupwise_leverage_weights[[i]],
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_random)
})
weight_re=TRUE
# Predict the random effects
groupwise_models <- lapply(1:n.groups, function(i) {
x = group_limits[i, ]
ranklm(y = marg_residuals[x[1]:x[2]],
X = Z[x[1]:x[2], , drop = FALSE],
intercept = intercepts$random,
weighted = weight_re, weights = groupwise_leverage_weights[[i]],
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_random)
})
# Predict the random effects
groupwise_models <- lapply(1:n.groups, function(i) {
x = group_limits[i, ]
ranklm(y = marg_residuals[x[1]:x[2]],
X = Z[x[1]:x[2], , drop = FALSE],
intercept = intercepts$random,
weighted = weight_re,
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_random)
})
b_hat <- matrix(unlist(lapply(groupwise_models, "[[", "coef")), n.groups, k, byrow = TRUE)
groupwise_leverage_weights <- lapply(groupwise_models, "[[", "weights")
groupwise_leverage_weights
# Calculate the residuals
cond_residuals <- c(unlist(apply(cbind(group_limits, b_hat), 1, function(x) {
if (intercepts$random) {
marg_residuals[x[1]:x[2]] - cbind(1, Z[x[1]:x[2], ]) %*% matrix(x[3:length(x)])
} else {
marg_residuals[x[1]:x[2]] - Z[x[1]:x[2], ] %*% matrix(x[3:length(x)])
}
})))
# Estimates for variance components
sigma_hat <- do.call(sd_function, c(list(cond_residuals), sd_function_arguments_fixed))
theta_hat <- apply(b_hat, 2, function(x) do.call(sd_function, c(list(x), sd_function_arguments_random)))
outlyingness_weights <- {
if (use_outlyingness_weights) {
sapply(2 * sigma_hat / abs(cond_residuals), min, 1)
} else { rep(1, n) } }
library(robustbase)
# Estimates for variance components
sigma_hat <- do.call(sd_function, c(list(cond_residuals), sd_function_arguments_fixed))
theta_hat <- apply(b_hat, 2, function(x) do.call(sd_function, c(list(x), sd_function_arguments_random)))
outlyingness_weights <- {
if (use_outlyingness_weights) {
sapply(2 * sigma_hat / abs(cond_residuals), min, 1)
} else { rep(1, n) } }
beta_init <- beta_hat
l <- 1
repeat {
# Store "old" set of coefficient estimates
beta_old <- beta_hat; theta_old <- theta_hat; sigma_old <- sigma_hat; b_hat_old <- b_hat
# Calculate and build the covariance matrix
Sigma_sq <- matrix(0, n, n)
if (length(theta_hat) > 1) {
Sigma_b <- diag(theta_hat^2)
} else { Sigma_b <- theta_hat^2 * diag(1) }
for (i in 1:nrow(group_limits)) {
Sigma_sq[group_limits[i, 1]:group_limits[i, 2],
group_limits[i, 1]:group_limits[i, 2]] <-
matpow(
sigma_hat^2 * diag(group_sizes[i]) +
{ if (intercepts$random) {
cbind(1, Z[group_limits[i, 1]:group_limits[i, 2], , drop = FALSE]) } else {
Z[group_limits[i, 1]:group_limits[i, 2], , drop = FALSE] }} %*%
Sigma_b %*%
t({ if (intercepts$random) {
cbind(1, Z[group_limits[i, 1]:group_limits[i, 2], , drop = FALSE]) } else {
Z[group_limits[i, 1]:group_limits[i, 2], , drop = FALSE] }}), -1/2)
}
# Rescale y and X
###
### We downweigh all y's that cause unusually large residuals. This would
### also happen in case of leverage points; which is not actually desired,
### right??!
###
y_star <- Sigma_sq %*% diag(outlyingness_weights) %*% y
X_star <- Sigma_sq %*% diag(outlyingness_weights) %*% X
# Fit the refined model
m <- ranklm(
y = y_star,
X = X_star,
intercept = FALSE, #intercepts$fixed,
weighted = weighted,
leverage_columns = leverage_columns,
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_fixed)
beta_hat <- m$coef
y_hat_tilde <- X %*% beta_hat #{ if (intercepts$fixed) { beta_hat[-1] } else { beta_hat } }
marg_residuals <- y - y_hat_tilde
if (intercepts$fixed) {
alpha <- do.call(mean_function, c(list(marg_residuals), mean_function_arguments_fixed))
marg_residuals <- marg_residuals - alpha
y_hat <- y_hat_tilde + alpha
beta_hat <- c(alpha, beta_hat)
}
groupwise_models <- lapply(1:n.groups, function(i) {
x = group_limits[i, ]
ranklm(y = marg_residuals[x[1]:x[2]],
X = Z[x[1]:x[2], , drop = FALSE],
intercept = intercepts$random,
weighted = weight_re, weights = groupwise_leverage_weights[[i]],
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_random)
})
b_hat <- matrix(unlist(lapply(groupwise_models, "[[", "coef")), n.groups, k, byrow = TRUE)
# groupwise_leverage_weights <- unlist(lapply(groupwise_models, "[[", "weights"))
cond_residuals <- c(unlist(apply(cbind(group_limits, b_hat), 1, function(x) {
if (intercepts$random) {
marg_residuals[x[1]:x[2]] - cbind(1, Z[x[1]:x[2], ]) %*% matrix(x[3:length(x)])
} else {
marg_residuals[x[1]:x[2]] - Z[x[1]:x[2], ] %*% matrix(x[3:length(x)])
}
})))
# print(beta_hat)
sigma_hat <- do.call(sd_function, c(list(cond_residuals), sd_function_arguments_fixed))
theta_hat <- apply(b_hat, 2, function(x) do.call(sd_function, c(list(x), sd_function_arguments_random)))
outlyingness_weights <- {
if (use_outlyingness_weights) {
sapply(2 * sigma_hat / abs(cond_residuals), min, 1)
} else { rep(1, n) } }
if (l >= maxit |
sum((beta_old - beta_hat)^2) / sum(beta_old^2) < tol &
sum((c(sigma_hat, theta_hat) - c(sigma_old, theta_old))^2) / sum(c(sigma_old, theta_old)^2) < tol
) break
l <- l + 1
}
l
devtools::install
devtools::install()
library(rankLME)
# Remove a possible intercept column from X and Z (in all cases -->
# die fügen wir immer von Hand dazu!)
if (length(unique(X[, 1])) == 1)  X <- X[, -1, drop = FALSE]
if (length(unique(Z[, 1])) == 1)  Z <- Z[, -1, drop = FALSE]
# Welche Spalte von X korrespondiert zu welcher Spalte in Z? Sollen wir einfach
# vorschreiben dass die richtig sortiert sind?
# For now mal schon!
Z_matching <- as.logical(apply(Z, 2, function(z) sum(apply(X, 2, function(x) all(z == x)))))
X_matching <- as.logical(apply(X, 2, function(z) sum(apply(Z, 2, function(x) all(z == x)))))
if (intercepts$fixed & intercepts$random) X_matching <- c(TRUE, X_matching)
# Set the model dimensions
n <- nrow(X)
p <- ncol(X) + intercepts$fixed
k <- ncol(Z) + intercepts$random
# Fit the first regression
m <- ranklm(X = X, y = y, intercept = intercepts$fixed, weighted = weighted,
leverage_columns = leverage_columns,
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_fixed)
# Coefficients and predicted values
beta_hat <- m$coef
y_hat <- { if (intercepts$fixed) { cbind(1, X) } else { X } } %*% beta_hat
weights <- m$weights
# Calculate the residuals
marg_residuals <- y - y_hat
# Predict the random effects
groupwise_models <- lapply(1:n.groups, function(i) {
x = group_limits[i, ]
ranklm(y = marg_residuals[x[1]:x[2]],
X = Z[x[1]:x[2], , drop = FALSE],
intercept = intercepts$random,
weighted = weight_re,
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_random)
})
b_hat <- matrix(unlist(lapply(groupwise_models, "[[", "coef")), n.groups, k, byrow = TRUE)
groupwise_leverage_weights <- lapply(groupwise_models, "[[", "weights")
# Calculate the residuals
cond_residuals <- c(unlist(apply(cbind(group_limits, b_hat), 1, function(x) {
if (intercepts$random) {
marg_residuals[x[1]:x[2]] - cbind(1, Z[x[1]:x[2], ]) %*% matrix(x[3:length(x)])
} else {
marg_residuals[x[1]:x[2]] - Z[x[1]:x[2], ] %*% matrix(x[3:length(x)])
}
})))
# Estimates for variance components
sigma_hat <- do.call(sd_function, c(list(cond_residuals), sd_function_arguments_fixed))
theta_hat <- apply(b_hat, 2, function(x) do.call(sd_function, c(list(x), sd_function_arguments_random)))
outlyingness_weights <- {
if (use_outlyingness_weights) {
sapply(2 * sigma_hat / abs(cond_residuals), min, 1)
} else { rep(1, n) } }
beta_init <- beta_hat
l <- 1
repeat {
# Store "old" set of coefficient estimates
beta_old <- beta_hat; theta_old <- theta_hat; sigma_old <- sigma_hat; b_hat_old <- b_hat
# Calculate and build the covariance matrix
Sigma_sq <- matrix(0, n, n)
if (length(theta_hat) > 1) {
Sigma_b <- diag(theta_hat^2)
} else { Sigma_b <- theta_hat^2 * diag(1) }
for (i in 1:nrow(group_limits)) {
Sigma_sq[group_limits[i, 1]:group_limits[i, 2],
group_limits[i, 1]:group_limits[i, 2]] <-
matpow(
sigma_hat^2 * diag(group_sizes[i]) +
{ if (intercepts$random) {
cbind(1, Z[group_limits[i, 1]:group_limits[i, 2], , drop = FALSE]) } else {
Z[group_limits[i, 1]:group_limits[i, 2], , drop = FALSE] }} %*%
Sigma_b %*%
t({ if (intercepts$random) {
cbind(1, Z[group_limits[i, 1]:group_limits[i, 2], , drop = FALSE]) } else {
Z[group_limits[i, 1]:group_limits[i, 2], , drop = FALSE] }}), -1/2)
}
# Rescale y and X
###
### We downweigh all y's that cause unusually large residuals. This would
### also happen in case of leverage points; which is not actually desired,
### right??!
###
y_star <- Sigma_sq %*% diag(outlyingness_weights) %*% y
X_star <- Sigma_sq %*% diag(outlyingness_weights) %*% X
# Fit the refined model
m <- ranklm(
y = y_star,
X = X_star,
intercept = FALSE, #intercepts$fixed,
weighted = weighted,
leverage_columns = leverage_columns,
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_fixed)
beta_hat <- m$coef
y_hat_tilde <- X %*% beta_hat #{ if (intercepts$fixed) { beta_hat[-1] } else { beta_hat } }
marg_residuals <- y - y_hat_tilde
if (intercepts$fixed) {
alpha <- do.call(mean_function, c(list(marg_residuals), mean_function_arguments_fixed))
marg_residuals <- marg_residuals - alpha
y_hat <- y_hat_tilde + alpha
beta_hat <- c(alpha, beta_hat)
}
groupwise_models <- lapply(1:n.groups, function(i) {
x = group_limits[i, ]
ranklm(y = marg_residuals[x[1]:x[2]],
X = Z[x[1]:x[2], , drop = FALSE],
intercept = intercepts$random,
weighted = weight_re, weights = groupwise_leverage_weights[[i]],
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_random)
})
b_hat <- matrix(unlist(lapply(groupwise_models, "[[", "coef")), n.groups, k, byrow = TRUE)
# groupwise_leverage_weights <- unlist(lapply(groupwise_models, "[[", "weights"))
cond_residuals <- c(unlist(apply(cbind(group_limits, b_hat), 1, function(x) {
if (intercepts$random) {
marg_residuals[x[1]:x[2]] - cbind(1, Z[x[1]:x[2], ]) %*% matrix(x[3:length(x)])
} else {
marg_residuals[x[1]:x[2]] - Z[x[1]:x[2], ] %*% matrix(x[3:length(x)])
}
})))
# print(beta_hat)
sigma_hat <- do.call(sd_function, c(list(cond_residuals), sd_function_arguments_fixed))
theta_hat <- apply(b_hat, 2, function(x) do.call(sd_function, c(list(x), sd_function_arguments_random)))
outlyingness_weights <- {
if (use_outlyingness_weights) {
sapply(2 * sigma_hat / abs(cond_residuals), min, 1)
} else { rep(1, n) } }
if (l >= maxit |
sum((beta_old - beta_hat)^2) / sum(beta_old^2) < tol &
sum((c(sigma_hat, theta_hat) - c(sigma_old, theta_old))^2) / sum(c(sigma_old, theta_old)^2) < tol
) break
l <- l + 1
}
l
weighted = weight_re = FALSE
# Remove a possible intercept column from X and Z (in all cases -->
# die fügen wir immer von Hand dazu!)
if (length(unique(X[, 1])) == 1)  X <- X[, -1, drop = FALSE]
if (length(unique(Z[, 1])) == 1)  Z <- Z[, -1, drop = FALSE]
### !!!!!!!!!!!!!!!!!!
# Match X and Z (for adjustment of random effects)
# Welche Spalte von X korrespondiert zu welcher Spalte in Z? Sollen wir einfach
# vorschreiben dass die richtig sortiert sind?
# For now mal schon!
Z_matching <- as.logical(apply(Z, 2, function(z) sum(apply(X, 2, function(x) all(z == x)))))
X_matching <- as.logical(apply(X, 2, function(z) sum(apply(Z, 2, function(x) all(z == x)))))
# Am besten wäre hier ein lookup table
# DAS FUNKTIONIERT NICHT WENN WIR MEHRERE RANDOM EFFECTS MATCHEN WOLLEN. INSGESAMT IST DAS JA IRGENDWIE BLÖDSINN,
# AM BESTEN WÄRE HIER ETWAS ZWEIDIMENSIONALES ODER?
if (intercepts$fixed & intercepts$random) X_matching <- c(TRUE, X_matching)
### !!!!!!!!!!!!!!!!!!!
# Set the model dimensions
n <- nrow(X)
p <- ncol(X) + intercepts$fixed
k <- ncol(Z) + intercepts$random
### Fit iterative rank estimate
# Fit the first regression
m <- ranklm(X = X, y = y, intercept = intercepts$fixed, weighted = weighted,
leverage_columns = leverage_columns,
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_fixed)
# Coefficients and predicted values
beta_hat <- m$coef
y_hat <- { if (intercepts$fixed) { cbind(1, X) } else { X } } %*% beta_hat
weights <- m$weights
# Calculate the residuals
marg_residuals <- y - y_hat
# Predict the random effects
groupwise_models <- lapply(1:n.groups, function(i) {
x = group_limits[i, ]
ranklm(y = marg_residuals[x[1]:x[2]],
X = Z[x[1]:x[2], , drop = FALSE],
intercept = intercepts$random,
weighted = weight_re,
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_random)
})
b_hat <- matrix(unlist(lapply(groupwise_models, "[[", "coef")), n.groups, k, byrow = TRUE)
groupwise_leverage_weights <- lapply(groupwise_models, "[[", "weights")
# Calculate the residuals
cond_residuals <- c(unlist(apply(cbind(group_limits, b_hat), 1, function(x) {
if (intercepts$random) {
marg_residuals[x[1]:x[2]] - cbind(1, Z[x[1]:x[2], ]) %*% matrix(x[3:length(x)])
} else {
marg_residuals[x[1]:x[2]] - Z[x[1]:x[2], ] %*% matrix(x[3:length(x)])
}
})))
# Estimates for variance components
sigma_hat <- do.call(sd_function, c(list(cond_residuals), sd_function_arguments_fixed))
theta_hat <- apply(b_hat, 2, function(x) do.call(sd_function, c(list(x), sd_function_arguments_random)))
outlyingness_weights <- {
if (use_outlyingness_weights) {
sapply(2 * sigma_hat / abs(cond_residuals), min, 1)
} else { rep(1, n) } }
beta_init <- beta_hat
l <- 1
repeat {
# Store "old" set of coefficient estimates
beta_old <- beta_hat; theta_old <- theta_hat; sigma_old <- sigma_hat; b_hat_old <- b_hat
# Calculate and build the covariance matrix
Sigma_sq <- matrix(0, n, n)
if (length(theta_hat) > 1) {
Sigma_b <- diag(theta_hat^2)
} else { Sigma_b <- theta_hat^2 * diag(1) }
for (i in 1:nrow(group_limits)) {
Sigma_sq[group_limits[i, 1]:group_limits[i, 2],
group_limits[i, 1]:group_limits[i, 2]] <-
matpow(
sigma_hat^2 * diag(group_sizes[i]) +
{ if (intercepts$random) {
cbind(1, Z[group_limits[i, 1]:group_limits[i, 2], , drop = FALSE]) } else {
Z[group_limits[i, 1]:group_limits[i, 2], , drop = FALSE] }} %*%
Sigma_b %*%
t({ if (intercepts$random) {
cbind(1, Z[group_limits[i, 1]:group_limits[i, 2], , drop = FALSE]) } else {
Z[group_limits[i, 1]:group_limits[i, 2], , drop = FALSE] }}), -1/2)
}
# Rescale y and X
###
### We downweigh all y's that cause unusually large residuals. This would
### also happen in case of leverage points; which is not actually desired,
### right??!
###
y_star <- Sigma_sq %*% diag(outlyingness_weights) %*% y
X_star <- Sigma_sq %*% diag(outlyingness_weights) %*% X
# Fit the refined model
m <- ranklm(
y = y_star,
X = X_star,
intercept = FALSE, #intercepts$fixed,
weighted = weighted,
leverage_columns = leverage_columns,
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_fixed)
beta_hat <- m$coef
y_hat_tilde <- X %*% beta_hat #{ if (intercepts$fixed) { beta_hat[-1] } else { beta_hat } }
marg_residuals <- y - y_hat_tilde
if (intercepts$fixed) {
alpha <- do.call(mean_function, c(list(marg_residuals), mean_function_arguments_fixed))
marg_residuals <- marg_residuals - alpha
y_hat <- y_hat_tilde + alpha
beta_hat <- c(alpha, beta_hat)
}
groupwise_models <- lapply(1:n.groups, function(i) {
x = group_limits[i, ]
ranklm(y = marg_residuals[x[1]:x[2]],
X = Z[x[1]:x[2], , drop = FALSE],
intercept = intercepts$random,
weighted = weight_re, weights = groupwise_leverage_weights[[i]],
mean_function = mean_function,
mean_function_arguments = mean_function_arguments_random)
})
b_hat <- matrix(unlist(lapply(groupwise_models, "[[", "coef")), n.groups, k, byrow = TRUE)
# groupwise_leverage_weights <- unlist(lapply(groupwise_models, "[[", "weights"))
cond_residuals <- c(unlist(apply(cbind(group_limits, b_hat), 1, function(x) {
if (intercepts$random) {
marg_residuals[x[1]:x[2]] - cbind(1, Z[x[1]:x[2], ]) %*% matrix(x[3:length(x)])
} else {
marg_residuals[x[1]:x[2]] - Z[x[1]:x[2], ] %*% matrix(x[3:length(x)])
}
})))
# print(beta_hat)
sigma_hat <- do.call(sd_function, c(list(cond_residuals), sd_function_arguments_fixed))
theta_hat <- apply(b_hat, 2, function(x) do.call(sd_function, c(list(x), sd_function_arguments_random)))
outlyingness_weights <- {
if (use_outlyingness_weights) {
sapply(2 * sigma_hat / abs(cond_residuals), min, 1)
} else { rep(1, n) } }
if (l >= maxit |
sum((beta_old - beta_hat)^2) / sum(beta_old^2) < tol &
sum((c(sigma_hat, theta_hat) - c(sigma_old, theta_old))^2) / sum(c(sigma_old, theta_old)^2) < tol
) break
l <- l + 1
}
l
devtools::install()
library(rankLME)
library(robustbase)
library(lme4)
library(robustlmm)
library(microbenchmark)
library(dplyr)
library(ggplot2)
setwd("~/gitAS/ADVANCE/AP3/robustmems")
colorcode <- c("REML" = "#458B74", "Rank" = "#FA681E", "SMDM" = "#0B4768",
"Weighted Rank" = "#FF69B4")
ltycode <- c("REML" = "dotdash", "Rank" = "solid", "SMDM" = "dotted", "Weighted Rank" = "dashed")
shapecode <- c("REML" = 16, "Rank" = 25, "SMDM" = 3, "Weighted Rank" = 23)
f = y ~ X1 + X2 + X3 + (1 + Z1 || g)
p = 4; k = 2
set.seed(251121)
increasing_group_size = lapply(
seq(10, 100, 10), function(x) raw_data(n = 20 * x, p = 4, k = 2, n.groups = 20, group_size = x)
)
m_inc_group_size <- vector("list", 10)
increasing_group_size = lapply(
seq(10, 100, 10), function(x) raw_data(n = 20 * x, p = 4, k = 2, n.groups = 20, group_size = x)
)
m_inc_group_size <- vector("list", 10)
for (i in 1:10) {
d <- increasing_group_size[[i]]
dat = with(d,
data.frame(
magrittr::set_colnames(cbind(y, X, Z, g),
c("y", paste0("X", 1:p - 1),
paste0("Z", 1:k - 1), "g")))
)
m_inc_group_size[[i]] <- microbenchmark(
#    "Rank" = ranklme(d$X, d$y, d$Z, d$g),
"Weighted Rank" = ranklme(X=d$X, y=d$y, Z=d$Z, g=d$g, weighted = TRUE),
#   "REML" = lmer(f, data = dat),
#  "SMDM" = rlmer(f, data = dat),
times = 5)
}
m_inc_group_size
setwd("~/gitAS/ADVANCE/AP3/robustmems")
load("runtimes_inc_group_size.RData")
m_inc_group_size[[1]]
devtools::install("rankLME")
setwd("~/gitAS/rankLME")
devtools::install("rankLME")
devtools::install()
ranklme(X=X, y=y, Z=Z, g=g, weighted=TRUE)
ranklme(X=X, y=y, Z=Z, g=g, weighted=FALSE)
ranklme(X=X, y=y, Z=Z, g=g, mcd=F)
mcd = ranklme(X=X, y=y, Z=Z, g=g, weighted = T, mcd=F)
mcd
mcd = ranklme(X=X, y=y, Z=Z, g=g, weighted = T, mcd=T)
mcd
devtools::install()
devtools::install()
devtools::install()
